{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l2UcbLv3oUnv",
    "outputId": "b3eaebe8-1159-4f37-d478-46fb95212d70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-q2o9wrxm\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-q2o9wrxm\n",
      "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ftfy in /home/xim/anaconda3/lib/python3.10/site-packages (from clip==1.0) (6.1.1)\n",
      "Requirement already satisfied: regex in /home/xim/anaconda3/lib/python3.10/site-packages (from clip==1.0) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /home/xim/anaconda3/lib/python3.10/site-packages (from clip==1.0) (4.65.0)\n",
      "Requirement already satisfied: torch in /home/xim/anaconda3/lib/python3.10/site-packages (from clip==1.0) (1.11.0)\n",
      "Requirement already satisfied: torchvision in /home/xim/anaconda3/lib/python3.10/site-packages (from clip==1.0) (0.15.2)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /home/xim/anaconda3/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.5)\n",
      "Requirement already satisfied: typing-extensions in /home/xim/.local/lib/python3.10/site-packages (from torch->clip==1.0) (4.8.0)\n",
      "Requirement already satisfied: numpy in /home/xim/anaconda3/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.23.5)\n",
      "Requirement already satisfied: requests in /home/xim/anaconda3/lib/python3.10/site-packages (from torchvision->clip==1.0) (2.31.0)\n",
      "Collecting torch (from clip==1.0)\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/8c/4d/17e07377c9c3d1a0c4eb3fde1c7c16b5a0ce6133ddbabc08ceef6b7f2645/torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata\n",
      "  Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/xim/anaconda3/lib/python3.10/site-packages (from torchvision->clip==1.0) (10.1.0)\n",
      "Requirement already satisfied: filelock in /home/xim/.local/lib/python3.10/site-packages (from torch->clip==1.0) (3.13.1)\n",
      "Requirement already satisfied: sympy in /home/xim/.local/lib/python3.10/site-packages (from torch->clip==1.0) (1.12)\n",
      "Requirement already satisfied: networkx in /home/xim/.local/lib/python3.10/site-packages (from torch->clip==1.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/xim/.local/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/xim/.local/lib/python3.10/site-packages (from torch->clip==1.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/xim/.local/lib/python3.10/site-packages (from torch->clip==1.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/xim/.local/lib/python3.10/site-packages (from torch->clip==1.0) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/xim/.local/lib/python3.10/site-packages (from torch->clip==1.0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/xim/.local/lib/python3.10/site-packages (from torch->clip==1.0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/xim/.local/lib/python3.10/site-packages (from torch->clip==1.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/xim/.local/lib/python3.10/site-packages (from torch->clip==1.0) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/xim/.local/lib/python3.10/site-packages (from torch->clip==1.0) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/xim/.local/lib/python3.10/site-packages (from torch->clip==1.0) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/xim/.local/lib/python3.10/site-packages (from torch->clip==1.0) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/xim/.local/lib/python3.10/site-packages (from torch->clip==1.0) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/xim/anaconda3/lib/python3.10/site-packages (from torch->clip==1.0) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/xim/anaconda3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->clip==1.0) (68.2.2)\n",
      "Requirement already satisfied: wheel in /home/xim/anaconda3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->clip==1.0) (0.41.2)\n",
      "Requirement already satisfied: cmake in /home/xim/.local/lib/python3.10/site-packages (from triton==2.0.0->torch->clip==1.0) (3.28.1)\n",
      "Requirement already satisfied: lit in /home/xim/.local/lib/python3.10/site-packages (from triton==2.0.0->torch->clip==1.0) (17.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/xim/.local/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/xim/anaconda3/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/xim/anaconda3/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/xim/anaconda3/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/xim/anaconda3/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/xim/.local/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
      "Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0\n",
      "    Uninstalling torch-1.11.0:\n",
      "      Successfully uninstalled torch-1.11.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.12.0 requires torch==1.11.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7I2n0pMloljO",
    "outputId": "59fea6a1-d2d8-49fd-a102-401e7201660f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xim/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "libcupti.so.11.7: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \u001b[38;5;66;03m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/__init__.py:229\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[1;32m    228\u001b[0m         _load_global_deps()\n\u001b[0;32m--> 229\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# torch._C module initialization code in C\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[0;31mImportError\u001b[0m: libcupti.so.11.7: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # plotting\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import json\n",
    "import torch\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import clip\n",
    "#from google.colab import drive\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "#drive.mount(\"/content/gdrive\")\n",
    "#os.chdir(\"dataset/train/train\")\n",
    "#os.chdir(\"dataset/test/test\")\n",
    "#os.chdir(\"dataset/val/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uIRRfwbUozP2"
   },
   "outputs": [],
   "source": [
    "def find_most_common_answer(answers):\n",
    "    answer_counter = Counter(answers)\n",
    "    most_common_answers = answer_counter.most_common()\n",
    "    most_common_answer, count = most_common_answers[0]\n",
    "    return most_common_answer\n",
    "\n",
    "def select_most_common_answers(df):\n",
    "    selected_answers = []\n",
    "    for idx, row in df.iterrows():\n",
    "        answers = [answer[\"answer\"] for answer in row[\"answers\"]]\n",
    "        selected_answer = find_most_common_answer(answers)\n",
    "\n",
    "        selected_answers.append({\"answer\": selected_answer\n",
    "        })\n",
    "\n",
    "    # Update the \"answer\" and \"answer_confidence\" columns in the DataFrame\n",
    "    df[[\"answer\"]] = pd.DataFrame(selected_answers)\n",
    "\n",
    "    return df.drop([\"answers\"], axis=1)\n",
    "\n",
    "def plot_loss(train_loss, val_loss):\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    plt.plot(epochs, train_loss, label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_img(path):\n",
    "    # Load the JPEG image\n",
    "    image = mpimg.imread(path)\n",
    "\n",
    "    # Plot the image\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # Remove axis ticks and labels\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1JVzZrqbpbc7"
   },
   "outputs": [],
   "source": [
    "def dataloader_json(path,test=False):\n",
    "    # Load the JSON file\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    # Create a DataFrame from the loaded JSON data\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    if test:\n",
    "        return df\n",
    "\n",
    "    return select_most_common_answers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "seBwPiSxplJ3",
    "outputId": "7329b8d3-f66e-4f28-c2dc-b4664c90c152"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/Annotations/Annotations/generated.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mdataloader_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset/Annotations/Annotations/generated.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m train_df\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mdataloader_json\u001b[0;34m(path, test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdataloader_json\u001b[39m(path,test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Load the JSON file\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m         data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from the loaded JSON data\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/Annotations/Annotations/generated.json'"
     ]
    }
   ],
   "source": [
    "train_df = dataloader_json(\"dataset/Annotations/Annotations/generated.json\")\n",
    "\n",
    "train_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YfEAXqdMvbnj",
    "outputId": "46bea46b-ad7c-48ab-894d-014364ffdb58"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_df['answer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "hBqdbYDCvJ9U",
    "outputId": "33f1b23a-f038-46e2-acbb-c682ef224fa4"
   },
   "outputs": [],
   "source": [
    "val_df = dataloader_json(\"dataset/Annotations/Annotations/val.json\")\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GIil0oBuzO2x",
    "outputId": "a2e9483c-e160-4938-9274-a1530bd7b518"
   },
   "outputs": [],
   "source": [
    "val_df['answer'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "YZdxgjB2zSlC",
    "outputId": "f8c6cf32-2819-486a-ccac-d5210cd15fb3"
   },
   "outputs": [],
   "source": [
    "data_df = pd.concat((train_df,val_df), axis =0,ignore_index=True)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pXCxsFV_zint",
    "outputId": "439f0c42-b2db-4962-d7ea-c5f0363947a1"
   },
   "outputs": [],
   "source": [
    "# Create a figure with six subplots\n",
    "fig, ((ax1, ax2)) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# Plot histogram for 'answerable' with a different color\n",
    "ax1.hist(pd.concat((train_df,val_df),axis = 0)['answerable'], bins=10, alpha=0.5, color='black', align='mid')\n",
    "ax1.set_title('Histogram of Answerable')\n",
    "ax1.set_xlabel('Values')\n",
    "ax1.set_ylabel('Frequency')\n",
    "\n",
    "# Plot histogram for 'answer_type' with a different color\n",
    "ax2.hist(pd.concat((train_df,val_df),axis = 0)['answer_type'], bins=10, alpha=0.5, color='red', align='mid')\n",
    "ax2.set_title('Histogram of Answer Type')\n",
    "ax2.set_xlabel('Values')\n",
    "ax2.set_ylabel('Frequency')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Create the histogram\n",
    "plt.figure(figsize=(18, 12))  # Adjust the figure size as per your preference\n",
    "counts, bins, patches = plt.hist(data_df.sample(n=50, random_state=42,replace=False)['answer'], bins=50, color='blue', alpha=0.5)\n",
    "\n",
    "bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Histogram of Answers')\n",
    "plt.xlabel('Answers')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.xticks(bin_centers)\n",
    "\n",
    "max_count = max(counts)\n",
    "plt.ylim(0, max_count + 1)\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ojvDrN5qzpOB"
   },
   "outputs": [],
   "source": [
    "ans_lb = LabelEncoder()\n",
    "data_df['answer'] = ans_lb.fit_transform(data_df['answer'])\n",
    "ans_type_lb = LabelEncoder()\n",
    "data_df['answer_type']= ans_type_lb.fit_transform(data_df['answer_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "600jNEO0ztO9",
    "outputId": "33896f49-4d56-4f43-bcf7-588ab61cd061"
   },
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "N8-nEUQEz0N5",
    "outputId": "36250f9e-cdbc-4ec1-b1ef-29076f8ff394"
   },
   "outputs": [],
   "source": [
    "val = data_df.iloc[20523:].reset_index(drop=True)\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DqjWEfKiQzPQ",
    "outputId": "458dc081-2586-438c-abfb-70e94edf253b"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_clip, preprocess = clip.load(\"ViT-L/14\", device=device)\n",
    "\n",
    "print(f'Using {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "rpUM5kUHROAn",
    "outputId": "0d647f13-f508-47f7-b248-150ba8295c40"
   },
   "outputs": [],
   "source": [
    "encodings = []\n",
    "for img , question in tqdm(zip(train_df['image'],train_df['question'])):\n",
    "    if \"train\" in img:\n",
    "\n",
    "        image = preprocess(Image.open(f'dataset/train/train/{img}').rotate(90)).unsqueeze(0).to(device)\n",
    "    elif \"test\" in img:\n",
    "       image = preprocess(Image.open(f'dataset/test/test/{img}')).unsqueeze(0).to(device)\n",
    "    else:\n",
    "        image = preprocess(Image.open(f'dataset/val/val/{img}')).unsqueeze(0).to(device)\n",
    "\n",
    "    text = clip.tokenize(question).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_encoding = model_clip.encode_image(image)\n",
    "        text_encoding = model_clip.encode_text(text)\n",
    "\n",
    "    encodings.append(torch.cat([image_encoding, text_encoding], dim=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encodings,\"encd768-90.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the indices for train-test split\n",
    "indices = np.arange(20523)\n",
    "\n",
    "# Perform train-test split\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.05, random_state=42, stratify=data_df.iloc[:20523]['answer_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices_aug = train_indices + 20643"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_df.iloc[train_indices] \n",
    "train = train.reset_index(drop=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_df.iloc[test_indices]\n",
    "test = test.reset_index(drop=True)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "embedding_size = 768\n",
    "classes = len(np.unique(ans_lb.classes_))\n",
    "aux_classes = len(np.unique(train['answer_type']))\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, aux_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, indices, answers, types, length):\n",
    "        self.indices = indices\n",
    "        self.answers = answers\n",
    "        self.types = types\n",
    "        self.length = length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "            if self.length <= 20523:\n",
    "                return encd[self.indices[index]].float() , torch.tensor(int(self.answers[index])), torch.tensor(int(self.types[index]))\n",
    "            \n",
    "            return encd[self.indices[index]].float() , torch.tensor(int(self.answers[index % (self.length/2)])), torch.tensor(int(self.types[index % (self.length/2)]))\n",
    "            \n",
    "    def __len__(self):\n",
    "          return self.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encd = torch.cat([torch.load('dataset/encALL.pt')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, indices, answers, types, length):\n",
    "        self.indices = indices\n",
    "        self.answers = answers\n",
    "        self.types = types\n",
    "        self.length = length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "            if self.length <= 20523:\n",
    "                return encd[self.indices[index]].float() , torch.tensor(int(self.answers[index])), torch.tensor(int(self.types[index]))\n",
    "            \n",
    "            return encd[self.indices[index]].float() , torch.tensor(int(self.answers[index % (self.length/2)])), torch.tensor(int(self.types[index % (self.length/2)]))\n",
    "            \n",
    "    def __len__(self):\n",
    "          return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = dataset(np.concatenate((train_indices, train_indices_aug)), train['answer'], train['answer_type'], len(train_indices)*2)\n",
    "\n",
    "\n",
    "valDataset = dataset(np.array(list(range(encd.shape[0] - 4319, encd.shape[0]))), val['answer'], val['answer_type'], 4319)\n",
    "\n",
    "train_dataloader = DataLoader(trainDataset, batch_size = BATCH_SIZE, shuffle = True, num_workers=0)\n",
    "\n",
    "val_dataloader = DataLoader(valDataset, batch_size = BATCH_SIZE, shuffle = True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.ln1 = nn.LayerNorm(embedding_size*2)\n",
    "        self.dp1 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(embedding_size* 2, 512)\n",
    "        \n",
    "        self.ln2 = torch.nn.LayerNorm(512)\n",
    "        self.dp2 = torch.nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = torch.nn.Linear(512, classes)\n",
    "        \n",
    "        self.fc_aux = torch.nn.Linear(512, aux_classes)\n",
    "        \n",
    "        self.lnaux = torch.nn.LayerNorm(aux_classes)\n",
    "        self.dpaux = torch.nn.Dropout(0.5)\n",
    "                \n",
    "        self.fc_gate = torch.nn.Linear(aux_classes, classes)\n",
    "        self.act_gate = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ln1(x)\n",
    "        x = self.dp1(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        x = self.ln2(x)\n",
    "        x = self.dp2(x)\n",
    "        \n",
    "#         aux\n",
    "        aux = self.fc_aux(x)\n",
    "#         aux = self.lnaux(aux)\n",
    "#         aux = self.dpaux(aux)\n",
    "        \n",
    "#         linear bottom\n",
    "        vqa = self.fc2(x)\n",
    "        \n",
    "        output = vqa * self.act_gate(self.fc_gate(aux))\n",
    "        \n",
    "        \n",
    "        return output,aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model,dataloader,val_loader, optimizer,train = True ):\n",
    "    if train:\n",
    "        model.train()\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    total_correct_ty = 0\n",
    "    total_samples_ty = 0\n",
    "    \n",
    "    for (data, ans , ans_type) in tqdm(dataloader):\n",
    "        data = data.to(device)\n",
    "        ans = ans.to(device)\n",
    "        ans_type = ans_type.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output , aux = model(data)\n",
    "        \n",
    "        loss_ans = loss(output, ans)\n",
    "        loss_type = loss(aux,ans_type)\n",
    "        loss_combined=loss_ans+loss_type\n",
    "        total_loss += loss_combined.item()\n",
    "        loss_combined.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "#         Answer Accurracy\n",
    "        _, predicted_labels = torch.max(output, dim=1)\n",
    "        correct = (predicted_labels == ans).sum().item()\n",
    "        total_correct += correct\n",
    "        total_samples += ans.size(0)\n",
    "        train_accuracy = total_correct / total_samples\n",
    "        \n",
    "#         Type Accuracy\n",
    "        _, predicted_labels_ty = torch.max(aux, dim=1)\n",
    "        correct_ty = (predicted_labels_ty == ans_type).sum().item()\n",
    "        total_correct_ty += correct_ty\n",
    "        total_samples_ty += ans_type.size(0)\n",
    "        train_accuracy_ty = total_correct_ty / total_samples_ty\n",
    "    \n",
    "    total_train_accuracy = (train_accuracy + train_accuracy_ty) / 2\n",
    "        \n",
    "        \n",
    "    if val_loader is not None:\n",
    "        model.eval()\n",
    "\n",
    "    # Initialize validation-specific variables\n",
    "    val_loss = 0.0\n",
    "    total_correct_val=0\n",
    "    total_samples_val=0\n",
    "    \n",
    "    total_correct_val_ty=0\n",
    "    total_samples_val_ty=0\n",
    "    \n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the validation data\n",
    "        for (data, ans , ans_type) in val_loader:\n",
    "            data = data.to(device)\n",
    "            ans = ans.to(device)\n",
    "            ans_type = ans_type.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output , aux = model(data)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss_ans = loss(output, ans)\n",
    "            loss_type = loss(aux,ans_type)\n",
    "            loss_combined=loss_ans+loss_type\n",
    "            val_loss += loss_combined.item()\n",
    "\n",
    "            # Update validation metrics\n",
    "            _, val_predicted = torch.max(output, dim=1)\n",
    "            correct_val = (val_predicted == ans).sum().item()\n",
    "            total_correct_val += correct_val\n",
    "            total_samples_val += ans.size(0)\n",
    "            val_accuracy = total_correct_val / total_samples_val\n",
    "            \n",
    "            _, val_predicted_ty = torch.max(aux, dim=1)\n",
    "            correct_val_ty = (val_predicted_ty == ans_type).sum().item()\n",
    "            total_correct_val_ty += correct_val_ty\n",
    "            total_samples_val_ty += ans_type.size(0)\n",
    "            val_accuracy_ty = total_correct_val_ty / total_samples_val_ty\n",
    "        \n",
    "        total_val_accuracy = (val_accuracy + val_accuracy_ty) / 2\n",
    "        \n",
    "    train_loss = total_loss/len(dataloader)\n",
    "    val_loss = val_loss/len(val_loader)\n",
    "    \n",
    "    print(f\"\\nTrain Loss: {train_loss:.4f} | AVG Train ACC: {total_train_accuracy * 100:.4f}% | Val Loss: {val_loss:.4f} | AVG Val ACC: {total_val_accuracy * 100:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nTrain ANS ACC: {train_accuracy * 100:.4f}% | VAL ANS ACC: {val_accuracy * 100:.4f}% | Train TYPE ACC: {train_accuracy_ty * 100:.4f}% | VAL TYPE ACC: {val_accuracy_ty * 100:.2f}%\\n\")\n",
    "        \n",
    "    return train_loss, val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Model()\n",
    "model = model.to(device)\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "epoch = 125\n",
    "training_loss = []\n",
    "val_loss = []\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=.1, threshold=1e-6)\n",
    "\n",
    "early_stopping_patience = 15  # Number of epochs to wait for improvement\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "for e in range(epoch):\n",
    "    print(f'Epoch: {e+1}', f'| LR: { optimizer.param_groups[0][\"lr\"] }')\n",
    "    trLoss, vlLoss = run_model(model,train_dataloader,val_dataloader,optimizer)    \n",
    "    training_loss.append(trLoss)\n",
    "    val_loss.append(vlLoss)\n",
    "    \n",
    "    scheduler.step(vlLoss)\n",
    "    \n",
    "    # Check if validation loss has improved\n",
    "    if vlLoss < best_val_loss:\n",
    "        best_val_loss = vlLoss\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # Check if early stopping criteria met\n",
    "    if epochs_without_improvement >= early_stopping_patience:\n",
    "        print(f\"\\nValidation loss hasn't improved for {early_stopping_patience} epochs. Early stopping.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset = dataset(test_indices,test['answer'], test['answer_type'],1027)\n",
    "test_dataloader = DataLoader(testDataset, batch_size=BATCH_SIZE , shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "total_correct_test=0\n",
    "total_samples_test=0\n",
    "    \n",
    "total_correct_test_ty=0\n",
    "total_samples_test_ty=0\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    # Iterate over the validation data\n",
    "    for (data, ans , ans_type) in test_dataloader:\n",
    "            data = data.to(device)\n",
    "            ans = ans.to(device)\n",
    "            ans_type = ans_type.to(device)\n",
    "            # Forward pass\n",
    "            output , aux = model(data)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss_ans = loss(output, ans)\n",
    "            loss_type = loss(aux,ans_type)\n",
    "            loss_combined=loss_ans+loss_type\n",
    "            test_loss += loss_combined.item()\n",
    "\n",
    "            # Update validation metrics\n",
    "            _, test_predicted = torch.max(output, dim=1)\n",
    "            correct_test = (test_predicted == ans).sum().item()\n",
    "            total_correct_test += correct_test\n",
    "            total_samples_test += ans.size(0)\n",
    "            test_accuracy = total_correct_test / total_samples_test\n",
    "            \n",
    "            _, test_predicted_ty = torch.max(aux, dim=1)\n",
    "            correct_test_ty = (test_predicted_ty == ans_type).sum().item()\n",
    "            total_correct_test_ty += correct_test_ty\n",
    "            total_samples_test_ty += ans_type.size(0)\n",
    "            test_accuracy_ty = total_correct_test_ty / total_samples_test_ty\n",
    "        \n",
    "    total_test_accuracy = (test_accuracy + test_accuracy_ty) / 2\n",
    "        \n",
    "        \n",
    "print(f\"Test TYPE ACC: {test_accuracy_ty * 100:.4f}% | Test ANS ACC: {test_accuracy * 100:.4f}% | AVG Test ACC: {total_test_accuracy * 100:.4f}% | Test Loss: {test_loss:.4f}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have two lists: train_loss and val_loss\n",
    "plot_loss(training_loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'modelv2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(question,image):\n",
    "    plot_img(image)\n",
    "    image = preprocess(Image.open(image)).unsqueeze(0).to(device)\n",
    "    text = clip.tokenize(question).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_encoding = model_clip.encode_image(image)\n",
    "        text_encoding = model_clip.encode_text(text)\n",
    "    return torch.cat([image_encoding,text_encoding],dim= -1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(question, image):\n",
    "    with torch.no_grad():\n",
    "        output , aux = model(encode(question,image))\n",
    "        _, test_predicted = torch.max(output, dim=1)\n",
    "        _, test_predicted_ty = torch.max(aux, dim=1)\n",
    "\n",
    "        print(f'Answer: {ans_lb.inverse_transform([test_predicted.item()])[0]}, Answer Type: {ans_type_lb.inverse_transform([test_predicted_ty.item()])[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset/train/train/VizWiz_train_00000000.jpg\"\n",
    "question = \"What is this?\"\n",
    "predict(question,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset/test/test/VizWiz_test_00000004.jpg\"\n",
    "question = \"What is this?\"\n",
    "predict(question,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset/test/test/VizWiz_test_00000011.jpg\"\n",
    "question = \"Whats the date?\"\n",
    "predict(question,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset/ranti.jpg\"\n",
    "question = \"Whatcolor is this?\"\n",
    "predict(question,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset/47.png\"\n",
    "question = \"what's the name of this product?\"\n",
    "predict(question,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset/image40.jpeg\"\n",
    "question = \"What's the name of this product?\"\n",
    "predict(question,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
